{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from torchvision import datasets, transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./data\", \n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)       \n",
    "\n",
    "mnist_test = datasets.MNIST(root=\"./data\", \n",
    "                            train=False, \n",
    "                            download=True, \n",
    "                            transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28) (10000,)\n",
      "(10000, 1, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = mnist_train.data.numpy().reshape(-1, 1, 28, 28)[:10000] / 255.0 \n",
    "y_train = mnist_train.targets.numpy()[:10000]\n",
    "X_test = mnist_test.data.numpy().reshape(-1, 1, 28, 28) / 255.0 \n",
    "y_test = mnist_test.targets.numpy() \n",
    "\n",
    "print(X_train.shape, y_train.shape) \n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions \n",
    "def relu(x): \n",
    "    return np.maximum(0, x) \n",
    "\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "# Linear layer\n",
    "def initialize_weights(input_size, output_size):\n",
    "    return np.random.randn(input_size, output_size) * np.sqrt(2.0 / input_size)\n",
    "\n",
    "def initialize_bias(output_size):\n",
    "    return np.zeros((1, output_size))\n",
    "\n",
    "def linear_forward(x, weights, bias):\n",
    "    return x @ weights + bias\n",
    "\n",
    "def linear_backward(grad_output, x, weights):\n",
    "    grad_weights = x.T @ grad_output\n",
    "    grad_bias = np.sum(grad_output, axis=0, keepdims=True)\n",
    "    grad_input = grad_output @ weights.T\n",
    "    return grad_input, grad_weights, grad_bias\n",
    "\n",
    "# Softmax and Cross-Entropy Loss\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    batch_size = y_pred.shape[0]\n",
    "    probabilities = softmax(y_pred)\n",
    "    correct_log_probs = np.log(probabilities[np.arange(batch_size), y_true])\n",
    "    loss = -np.sum(correct_log_probs) / batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.weights1 = initialize_weights(input_size, hidden_size)\n",
    "        self.bias1 = initialize_bias(hidden_size)\n",
    "        self.weights2 = initialize_weights(hidden_size, output_size)\n",
    "        self.bias2 = initialize_bias(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        fc1_input = x.reshape(batch_size, -1)\n",
    "        fc1_output = linear_forward(fc1_input, self.weights1, self.bias1)\n",
    "        relu_output = relu(fc1_output)\n",
    "        fc2_output = linear_forward(relu_output, self.weights2, self.bias2)\n",
    "        return fc2_output, (fc1_input, fc1_output, relu_output)\n",
    "\n",
    "    def backward(self, grad_output, cache):\n",
    "        x, fc1_output, relu_output = cache\n",
    "\n",
    "        grad_fc2, grad_weights2, grad_bias2 = linear_backward(grad_output, relu_output, self.weights2)\n",
    "        grad_relu = grad_fc2 * relu_derivative(fc1_output)\n",
    "        grad_fc1, grad_weights1, grad_bias1 = linear_backward(grad_relu, x, self.weights1)\n",
    "        return grad_weights1, grad_bias1, grad_weights2, grad_bias2\n",
    "\n",
    "    def update_weights(self, grad_weights1, grad_bias1, grad_weights2, grad_bias2, learning_rate):\n",
    "        self.weights1 -= learning_rate * grad_weights1\n",
    "        self.bias1 -= learning_rate * grad_bias1\n",
    "        self.weights2 -= learning_rate * grad_weights2\n",
    "        self.bias2 -= learning_rate * grad_bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_test, y_test, batch_size, epochs, learning_rate):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            batch_X = X_train[i:i+batch_size]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "            y_pred, cache = model.forward(batch_X)\n",
    "            loss = cross_entropy_loss(y_pred, batch_y)\n",
    "\n",
    "            softmax_probs = softmax(y_pred)\n",
    "            y_true_one_hot = np.zeros_like(y_pred)\n",
    "            y_true_one_hot[np.arange(len(batch_y)), batch_y] = 1\n",
    "            grad_output = softmax_probs - y_true_one_hot\n",
    "\n",
    "            grad_weights1, grad_bias1, grad_weights2, grad_bias2 = model.backward(grad_output, cache)\n",
    "            model.update_weights(grad_weights1, grad_bias1, grad_weights2, grad_bias2, learning_rate)\n",
    "\n",
    "            if (i//batch_size) % 100 == 0:\n",
    "                print(f\"Iteration: {i//batch_size} Loss: {loss:.4f}\")\n",
    "\n",
    "        y_pred, _ = model.forward(X_test)\n",
    "        test_loss = cross_entropy_loss(y_pred, y_test)\n",
    "        accuracy = np.mean(np.argmax(y_pred, axis=1) == y_test)\n",
    "        print(f\"Epoch {epoch+1} - Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Iteration: 0 Loss: 2.3563\n",
      "Iteration: 100 Loss: 1.8949\n",
      "Iteration: 200 Loss: 1.7481\n",
      "Iteration: 300 Loss: 1.0836\n",
      "Iteration: 400 Loss: 1.2747\n",
      "Iteration: 500 Loss: 1.4692\n",
      "Iteration: 600 Loss: 0.9899\n",
      "Iteration: 700 Loss: 1.6241\n",
      "Iteration: 800 Loss: 0.9219\n",
      "Iteration: 900 Loss: 0.5267\n",
      "Iteration: 1000 Loss: 0.1632\n",
      "Iteration: 1100 Loss: 0.9588\n",
      "Iteration: 1200 Loss: 1.0192\n",
      "Iteration: 1300 Loss: 0.3997\n",
      "Iteration: 1400 Loss: 0.6763\n",
      "Iteration: 1500 Loss: 0.2416\n",
      "Iteration: 1600 Loss: 0.1340\n",
      "Iteration: 1700 Loss: 0.2832\n",
      "Iteration: 1800 Loss: 0.8226\n",
      "Iteration: 1900 Loss: 0.5195\n",
      "Iteration: 2000 Loss: 0.1383\n",
      "Iteration: 2100 Loss: 0.2543\n",
      "Iteration: 2200 Loss: 0.1751\n",
      "Iteration: 2300 Loss: 0.2692\n",
      "Iteration: 2400 Loss: 0.5231\n",
      "Epoch 1 - Test Loss: 0.4532, Test Accuracy: 0.8781\n",
      "Epoch 2/3\n",
      "Iteration: 0 Loss: 0.4940\n",
      "Iteration: 100 Loss: 0.0736\n",
      "Iteration: 200 Loss: 0.7332\n",
      "Iteration: 300 Loss: 0.3142\n",
      "Iteration: 400 Loss: 0.4679\n",
      "Iteration: 500 Loss: 0.7211\n",
      "Iteration: 600 Loss: 0.2842\n",
      "Iteration: 700 Loss: 1.5920\n",
      "Iteration: 800 Loss: 0.4573\n",
      "Iteration: 900 Loss: 0.1795\n",
      "Iteration: 1000 Loss: 0.0335\n",
      "Iteration: 1100 Loss: 0.7909\n",
      "Iteration: 1200 Loss: 0.8526\n",
      "Iteration: 1300 Loss: 0.1346\n",
      "Iteration: 1400 Loss: 0.4470\n",
      "Iteration: 1500 Loss: 0.1171\n",
      "Iteration: 1600 Loss: 0.0524\n",
      "Iteration: 1700 Loss: 0.1532\n",
      "Iteration: 1800 Loss: 0.5467\n",
      "Iteration: 1900 Loss: 0.4392\n",
      "Iteration: 2000 Loss: 0.0537\n",
      "Iteration: 2100 Loss: 0.1459\n",
      "Iteration: 2200 Loss: 0.1485\n",
      "Iteration: 2300 Loss: 0.2071\n",
      "Iteration: 2400 Loss: 0.2937\n",
      "Epoch 2 - Test Loss: 0.3637, Test Accuracy: 0.8994\n",
      "Epoch 3/3\n",
      "Iteration: 0 Loss: 0.3922\n",
      "Iteration: 100 Loss: 0.0272\n",
      "Iteration: 200 Loss: 0.6099\n",
      "Iteration: 300 Loss: 0.2669\n",
      "Iteration: 400 Loss: 0.2961\n",
      "Iteration: 500 Loss: 0.5612\n",
      "Iteration: 600 Loss: 0.1983\n",
      "Iteration: 700 Loss: 1.5875\n",
      "Iteration: 800 Loss: 0.3002\n",
      "Iteration: 900 Loss: 0.1133\n",
      "Iteration: 1000 Loss: 0.0193\n",
      "Iteration: 1100 Loss: 0.6567\n",
      "Iteration: 1200 Loss: 0.7873\n",
      "Iteration: 1300 Loss: 0.0973\n",
      "Iteration: 1400 Loss: 0.4012\n",
      "Iteration: 1500 Loss: 0.0960\n",
      "Iteration: 1600 Loss: 0.0384\n",
      "Iteration: 1700 Loss: 0.1248\n",
      "Iteration: 1800 Loss: 0.4009\n",
      "Iteration: 1900 Loss: 0.3920\n",
      "Iteration: 2000 Loss: 0.0335\n",
      "Iteration: 2100 Loss: 0.1192\n",
      "Iteration: 2200 Loss: 0.1540\n",
      "Iteration: 2300 Loss: 0.1838\n",
      "Iteration: 2400 Loss: 0.2048\n",
      "Epoch 3 - Test Loss: 0.3267, Test Accuracy: 0.9087\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_size = 784  # 28x28 pixels\n",
    "    hidden_size = 256\n",
    "    output_size = 10  # 10 digits\n",
    "    \n",
    "    model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "    \n",
    "    batch_size = 4\n",
    "    epochs = 3\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    train(model, X_train, y_train, X_test, y_test, batch_size, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
