{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torchvision \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "TRAIN_SIZE = 10000\n",
    "epochs = 3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.mnist.MNIST, torchvision.datasets.mnist.MNIST)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root=\"./data\", \n",
    "                                train = True, \n",
    "                                transform = transform, \n",
    "                                download = True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=\"./data\", \n",
    "                                train = False, \n",
    "                                transform = transform, \n",
    "                                download = True)\n",
    "\n",
    "type(train_dataset),type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader,\n",
       " torch.utils.data.dataloader.DataLoader)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False)\n",
    "\n",
    "type(train_loader), type(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset) # 60000, 10000\n",
    "\n",
    "# Pre-allocate tensors of the appropriate size \n",
    "train_data = torch.zeros(60000, 1, 28, 28) \n",
    "train_labels = torch.zeros(60000, dtype=torch.long) \n",
    "test_data = torch.zeros(10000, 1, 28, 28)\n",
    "test_labels = torch.zeros(10000, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.float32\n",
      "torch.Size([10000, 1, 28, 28]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Load all training data into RAM \n",
    "\n",
    "for idx, (data, label) in enumerate(train_loader): \n",
    "    start_idx = idx * batch_size \n",
    "    end_idx = start_idx + data.size(0) \n",
    "    train_data[start_idx:end_idx] = data\n",
    "    train_labels[start_idx:end_idx] = label\n",
    "\n",
    "print(train_data.shape, train_data.dtype)\n",
    "\n",
    "# Load all test data into RAM \n",
    "\n",
    "for idx, (data, label) in enumerate(test_loader): \n",
    "    start_idx = idx * batch_size \n",
    "    end_idx = start_idx + data.size(0) \n",
    "    test_data[start_idx:end_idx] = data\n",
    "    test_labels[start_idx:end_idx] = label      \n",
    "\n",
    "print(test_data.shape, test_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters per epoch: 312\n"
     ]
    }
   ],
   "source": [
    "iters_per_epoch = TRAIN_SIZE // batch_size\n",
    "print(\"Iters per epoch:\", iters_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, num_classes): \n",
    "        super(MLP, self).__init__() \n",
    "        self.fc1 = nn.Linear(in_features, hidden_features) \n",
    "        self.relu = nn.ReLU() \n",
    "        self.fc2 = nn.Linear(hidden_features, num_classes) \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = x.reshape(batch_size, 28*28) \n",
    "        x = self.fc1(x) \n",
    "        x = self.relu(x) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(in_features=28*28, hidden_features=256, num_classes=10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model \n",
    "\n",
    "def train(model, criterion, optimizer, epoch):\n",
    "    model.train() \n",
    "    running_loss = 0.0 \n",
    "\n",
    "    for i in range(iters_per_epoch):\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        data = train_data[i * batch_size : (i + 1) * batch_size] \n",
    "        targets = train_labels[i * batch_size : (i + 1) * batch_size] \n",
    "\n",
    "        start = time.time() \n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() \n",
    "        end = time.time()\n",
    "        running_loss += loss.item() \n",
    "\n",
    "        if i % 100 == 99 or i == 0: \n",
    "            print(f\"Epoch: {epoch+1}, Iter: {i+1}, Loss: {loss}\")\n",
    "            print(f\"Time per batch: {(end-start) * 1e3:.4f} sec\")\n",
    "            running_loss = 0.0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data, test_labels): \n",
    "    device = torch.device(\"cpu\") \n",
    "    model.to(device) \n",
    "    model.eval() \n",
    "\n",
    "    total_batch_accuracy = torch.tensor(0.0, device=device) \n",
    "    num_batches = 0 \n",
    "    with torch.no_grad(): \n",
    "        for i in range(len(test_data) // batch_size): \n",
    "            data = test_data[i * batch_size : (i + 1) * batch_size] \n",
    "            target = test_labels[i * batch_size : (i + 1) * batch_size] \n",
    "            outputs = model(data) \n",
    "\n",
    "            _, predicted = torch.max(outputs, 1) \n",
    "            correct_batch = (predicted == target).sum().item() \n",
    "            total_batch = target.size(0) \n",
    "            if total_batch != 0: \n",
    "                batch_accuracy = correct_batch / total_batch \n",
    "                total_batch_accuracy += batch_accuracy \n",
    "                num_batches += 1 \n",
    "\n",
    "    avg_batch_accuracy = total_batch_accuracy / num_batches \n",
    "    print(f\"Average Batch Accuracy: {avg_batch_accuracy * 100: .2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 1, Loss: 2.3500967025756836\n",
      "Time per batch: 143.3296 sec\n",
      "Epoch: 1, Iter: 100, Loss: 0.32422706484794617\n",
      "Time per batch: 3.2609 sec\n",
      "Epoch: 1, Iter: 200, Loss: 0.3650629222393036\n",
      "Time per batch: 7.0124 sec\n",
      "Epoch: 1, Iter: 300, Loss: 0.19618771970272064\n",
      "Time per batch: 0.0000 sec\n",
      "Average Batch Accuracy:  92.39%\n",
      "Epoch: 2, Iter: 1, Loss: 0.42112624645233154\n",
      "Time per batch: 8.1015 sec\n",
      "Epoch: 2, Iter: 100, Loss: 0.2059713751077652\n",
      "Time per batch: 0.0000 sec\n",
      "Epoch: 2, Iter: 200, Loss: 0.1865643709897995\n",
      "Time per batch: 5.5268 sec\n",
      "Epoch: 2, Iter: 300, Loss: 0.09503141045570374\n",
      "Time per batch: 2.0816 sec\n",
      "Average Batch Accuracy:  94.14%\n",
      "Epoch: 3, Iter: 1, Loss: 0.19763953983783722\n",
      "Time per batch: 0.0000 sec\n",
      "Epoch: 3, Iter: 100, Loss: 0.1086488589644432\n",
      "Time per batch: 4.5102 sec\n",
      "Epoch: 3, Iter: 200, Loss: 0.10490388423204422\n",
      "Time per batch: 1.0335 sec\n",
      "Epoch: 3, Iter: 300, Loss: 0.05188275873661041\n",
      "Time per batch: 0.0000 sec\n",
      "Average Batch Accuracy:  94.49%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    for epoch in range(epochs): \n",
    "        train(model, criterion, optimizer, epoch) \n",
    "        evaluate(model, test_data, test_labels) \n",
    "\n",
    "    print(\"Finished Training\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
